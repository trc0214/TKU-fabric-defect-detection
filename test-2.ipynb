{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e0f13a",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "img_dir = \"./testure test images/\"\n",
    "\n",
    "test_images = [\n",
    "    os.path.join(img_dir, 'image1.png'),\n",
    "    os.path.join(img_dir, 'image2.png'),\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    os.path.join(img_dir, 'image1_groundtruth.png'),\n",
    "    os.path.join(img_dir, 'image2_groundtruth.png'),\n",
    "]\n",
    "### 擴增與訓練說明\n",
    "- 若要調整擴增筆數，修改第二格中的 `N_SAMPLES`.\n",
    "- 增強缺陷樣式可在 `add_synthetic_defects` 中加更多型態 (例如格狀、斜切片、局部模糊區)。\n",
    "- 前處理 `texture_normalize` 可調 `open_size` 與 `fft_remove_ratio` 抑制重複花紋。\n",
    "- 訓練迭代數由 `EPOCHS` 控制，增大可提升擬合，但要注意過擬合。\n",
    "- 若有 GPU 會自動使用。若記憶體不足可降低 `batch_size`.\n",
    "- 目前 `pred_mask` 以白色表示缺陷 (便於人工檢視)。若要與其他方法統一，可改成 0=缺陷,255=非缺陷。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569bb26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base images: 2\n",
      "Augmented samples: 100\n",
      "Device: cpu\n",
      "Augmented samples: 100\n",
      "Device: cpu\n",
      "Epoch 1/10 Train BCE 0.5634 Dice 0.9035 | Val BCE 0.9049 Dice 0.9363\n",
      "Epoch 1/10 Train BCE 0.5634 Dice 0.9035 | Val BCE 0.9049 Dice 0.9363\n",
      "Epoch 2/10 Train BCE 0.4332 Dice 0.8792 | Val BCE 0.4231 Dice 0.9187\n",
      "Epoch 2/10 Train BCE 0.4332 Dice 0.8792 | Val BCE 0.4231 Dice 0.9187\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 161\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,EPOCHS+\u001b[32m1\u001b[39m):\n\u001b[32m    160\u001b[39m     model.train(); tb=\u001b[32m0\u001b[39m; td=\u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m train_dl: x=x.to(device); y=y.to(device); opt.zero_grad(); o=model(x); lb=bce(o,y); ld=dice_loss(o,y); loss=lb+ld; loss.backward(); opt.step(); tb+=lb.item(); td+=ld.item()\n\u001b[32m    162\u001b[39m     model.eval(); vb=\u001b[32m0\u001b[39m; vd=\u001b[32m0\u001b[39m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 擴增原始 2 張灰階影像至 100 筆並訓練輕量 U-Net\n",
    "# 缺陷顯示規則: 0 = 缺陷(黑), 255 = 非缺陷(白)\n",
    "# -------------------------------------------------------------\n",
    "import os, random, cv2, numpy as np, matplotlib.pyplot as plt\n",
    "random.seed(42); np.random.seed(42)\n",
    "# Resolve base image directory robustly (typo handling)\n",
    "candidates = ['./texture test images', './texture test images/', './testure test images', './testure test images/']\n",
    "BASE_DIR = None\n",
    "for _c in candidates:\n",
    "    if os.path.isdir(_c):\n",
    "        BASE_DIR = _c\n",
    "        break\n",
    "if BASE_DIR is None:\n",
    "    raise FileNotFoundError('No texture image directory found among candidates: ' + ', '.join(candidates))\n",
    "IMG_FILES = ['image1.png','image2.png']\n",
    "GT_FILES  = ['image1_groundtruth.png','image2_groundtruth.png']\n",
    "imgs = []; gts = []\n",
    "for f, g in zip(IMG_FILES, GT_FILES):\n",
    "    ip = os.path.join(BASE_DIR,f)\n",
    "    gp = os.path.join(BASE_DIR,g)\n",
    "    im = cv2.imread(ip, cv2.IMREAD_UNCHANGED)\n",
    "    if im is None: raise FileNotFoundError(ip)\n",
    "    if im.ndim==3: im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    gt = cv2.imread(gp, cv2.IMREAD_UNCHANGED) if os.path.isfile(gp) else None\n",
    "    if gt is None: gt = np.ones_like(im,dtype=np.uint8)*255\n",
    "    if gt.ndim==3: gt = cv2.cvtColor(gt, cv2.COLOR_BGR2GRAY)\n",
    "    gt = cv2.resize(gt,(im.shape[1],im.shape[0]),interpolation=cv2.INTER_NEAREST)\n",
    "    imgs.append(im); gts.append(gt)\n",
    "print('Loaded base images:', len(imgs))\n",
    "# -------- 紋理正規化 (改良版: 保留缺陷特徵) --------\n",
    "def texture_normalize(gray, open_size=51):\n",
    "    \"\"\"使用 top-hat 變換保留局部異常，避免過度均質化\"\"\"\n",
    "    k = max(3, open_size|1)\n",
    "    ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(k,k))\n",
    "    # Top-hat: 突顯比背景亮的區域 (某些缺陷)\n",
    "    tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, ker)\n",
    "    # Black-hat: 突顯比背景暗的區域 (另一些缺陷)\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, ker)\n",
    "    # 組合兩者，保留雙向異常\n",
    "    norm = cv2.add(gray, tophat)\n",
    "    norm = cv2.subtract(norm, blackhat)\n",
    "    # 輕微高斯濾波去除高頻噪音但保留缺陷邊緣\n",
    "    norm = cv2.GaussianBlur(norm, (3,3), 0.5)\n",
    "    # CLAHE 增強對比度而不破壞局部特徵\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    norm = clahe.apply(norm)\n",
    "    return norm\n",
    "# -------- 合成缺陷 (線/孔/斑點/裂紋) --------\n",
    "def synth_defects(img, mask, max_ops=3):\n",
    "    h,w = img.shape\n",
    "    out = img.copy(); m = mask.copy()\n",
    "    for _ in range(random.randint(1,max_ops)):\n",
    "        t = random.choice(['line','hole','dots','crack'])\n",
    "        if t=='line':\n",
    "            x1,y1 = random.randint(0,w-1), random.randint(0,h-1)\n",
    "            x2,y2 = random.randint(0,w-1), random.randint(0,h-1)\n",
    "            thick = random.randint(2,7)\n",
    "            cv2.line(out,(x1,y1),(x2,y2),color=random.randint(0,35),thickness=thick)\n",
    "            cv2.line(m,(x1,y1),(x2,y2),color=0,thickness=thick)\n",
    "        elif t=='hole':\n",
    "            cx,cy = random.randint(0,w-1), random.randint(0,h-1); r=random.randint(10,28)\n",
    "            cv2.circle(out,(cx,cy),r,color=random.randint(0,40),thickness=-1)\n",
    "            cv2.circle(m,(cx,cy),r,color=0,thickness=-1)\n",
    "        elif t=='dots':\n",
    "            for __ in range(random.randint(8,25)):\n",
    "                dx,dy = random.randint(0,w-1), random.randint(0,h-1)\n",
    "                out[dy,dx]=random.randint(0,50); m[dy,dx]=0\n",
    "        elif t=='crack':\n",
    "            pts=[]; steps=random.randint(5,12); x,y=random.randint(0,w-1),random.randint(0,h-1)\n",
    "            for __ in range(steps):\n",
    "                pts.append((x,y)); x+=random.randint(-14,14); y+=random.randint(-14,14)\n",
    "                x=max(0,min(w-1,x)); y=max(0,min(h-1,y))\n",
    "            for a,b in zip(pts[:-1],pts[1:]):\n",
    "                cv2.line(out,a,b,color=random.randint(0,30),thickness=random.randint(1,4))\n",
    "                cv2.line(m,a,b,color=0,thickness=random.randint(1,4))\n",
    "    return out,m\n",
    "# -------- 幾何 + 強度擴增 --------\n",
    "def aug_geom_intensity(img, mask):\n",
    "    h,w = img.shape; k=random.randint(0,3)\n",
    "    img2=np.rot90(img,k); mask2=np.rot90(mask,k)\n",
    "    if random.random()<0.5: img2=np.flipud(img2); mask2=np.flipud(mask2)\n",
    "    if random.random()<0.5: img2=np.fliplr(img2); mask2=np.fliplr(mask2)\n",
    "    scale=random.uniform(0.85,1.25); nh,nw=int(h*scale),int(w*scale)\n",
    "    img_rs=cv2.resize(img2,(nw,nh),interpolation=cv2.INTER_LINEAR); mask_rs=cv2.resize(mask2,(nw,nh),interpolation=cv2.INTER_NEAREST)\n",
    "    canvas_i=np.full((h,w),np.mean(img_rs),dtype=img.dtype); canvas_m=np.full((h,w),255,dtype=mask.dtype)\n",
    "    y0=(h-nh)//2; x0=(w-nw)//2; y1=y0+nh; x1=x0+nw\n",
    "    y0=max(0,y0); x0=max(0,x0); y1=min(h,y1); x1=min(w,x1)\n",
    "    img_crop=img_rs[:y1-y0,:x1-x0]; mask_crop=mask_rs[:y1-y0,:x1-x0]\n",
    "    canvas_i[y0:y1,x0:x1]=img_crop; canvas_m[y0:y1,x0:x1]=mask_crop\n",
    "    img2,mask2=canvas_i,canvas_m\n",
    "    if random.random()<0.8: # gamma\n",
    "        gamma=random.uniform(0.7,1.5); g=(img2/255.0)**gamma*255; img2=np.clip(g,0,255).astype(np.uint8)\n",
    "    if random.random()<0.6: # noise\n",
    "        noise=np.random.normal(0,random.uniform(3,12),img2.shape); img2=np.clip(img2+noise,0,255).astype(np.uint8)\n",
    "    if random.random()<0.4: img2=cv2.GaussianBlur(img2,(3,3),0)\n",
    "    if random.random()<0.5: # contrast/brightness\n",
    "        alpha=random.uniform(0.85,1.3); beta=random.uniform(-20,20); img2=np.clip(alpha*img2+beta,0,255).astype(np.uint8)\n",
    "    return img2,mask2\n",
    "# -------- 生成擴增樣本 --------\n",
    "N_SAMPLES=100\n",
    "augX=[]; augY=[]\n",
    "base_norm=[texture_normalize(im) for im in imgs]\n",
    "for i in range(N_SAMPLES):\n",
    "    idx=random.randint(0,len(base_norm)-1)\n",
    "    im=base_norm[idx]; gt=gts[idx]\n",
    "    im_a,gt_a=aug_geom_intensity(im,gt)\n",
    "    if random.random()<0.9: im_a,gt_a=synth_defects(im_a,gt_a,max_ops=random.randint(1,4))\n",
    "    augX.append(im_a); augY.append(gt_a)\n",
    "print('Augmented samples:', len(augX))\n",
    "# -------- 建立 PyTorch 資料集 --------\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'; print('Device:',device)\n",
    "class DefectDataset(Dataset):\n",
    "    def __init__(self, imgs, masks): self.imgs=imgs; self.masks=masks\n",
    "    def __len__(self): return len(self.imgs)\n",
    "    def __getitem__(self,i):\n",
    "        im=self.imgs[i].astype(np.float32)/255.0\n",
    "        m=(self.masks[i]==0).astype(np.float32) # defect 1\n",
    "        return torch.from_numpy(im[None,...]), torch.from_numpy(m[None,...])\n",
    "# split train/val\n",
    "indices=list(range(N_SAMPLES)); random.shuffle(indices)\n",
    "val_n=int(N_SAMPLES*0.15); val_set=set(indices[:val_n])\n",
    "trainX=[augX[i] for i in indices if i not in val_set]; trainY=[augY[i] for i in indices if i not in val_set]\n",
    "valX=[augX[i] for i in indices if i in val_set]; valY=[augY[i] for i in indices if i in val_set]\n",
    "train_ds=DefectDataset(trainX,trainY); val_ds=DefectDataset(valX,valY)\n",
    "train_dl=DataLoader(train_ds,batch_size=8,shuffle=True); val_dl=DataLoader(val_ds,batch_size=8)\n",
    "# -------- 輕量 U-Net --------\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,i,o): super().__init__(); self.c=nn.Sequential(nn.Conv2d(i,o,3,padding=1),nn.BatchNorm2d(o),nn.ReLU(True),nn.Conv2d(o,o,3,padding=1),nn.BatchNorm2d(o),nn.ReLU(True))\n",
    "    def forward(self,x): return self.c(x)\n",
    "class TinyUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b1 = Block(1,32)\n",
    "        self.b2 = Block(32,64)\n",
    "        self.b3 = Block(64,128)\n",
    "        self.p = nn.MaxPool2d(2)\n",
    "        self.up2 = nn.ConvTranspose2d(128,64,2,2)\n",
    "        self.d2 = Block(128,64)\n",
    "        self.up1 = nn.ConvTranspose2d(64,32,2,2)\n",
    "        self.d1 = Block(64,32)\n",
    "        self.out = nn.Conv2d(32,1,1)\n",
    "    def forward(self,x):\n",
    "        e1 = self.b1(x)\n",
    "        e2 = self.b2(self.p(e1))\n",
    "        e3 = self.b3(self.p(e2))\n",
    "        u2 = self.up2(e3)\n",
    "        u2 = torch.cat([u2,e2],1)\n",
    "        u2 = self.d2(u2)\n",
    "        u1 = self.up1(u2)\n",
    "        u1 = torch.cat([u1,e1],1)\n",
    "        u1 = self.d1(u1)\n",
    "        return self.out(u1)\n",
    "def dice_loss(logits, targets, eps=1e-6):\n",
    "    probs=torch.sigmoid(logits); num=2*(probs*targets).sum(); den=probs.sum()+targets.sum()+eps; return 1-num/den\n",
    "model=TinyUNet().to(device); opt=torch.optim.Adam(model.parameters(),lr=1e-3); bce=nn.BCEWithLogitsLoss()\n",
    "EPOCHS=10; train_hist=[]; val_hist=[]\n",
    "for ep in range(1,EPOCHS+1):\n",
    "    model.train(); tb=0; td=0\n",
    "    for x,y in train_dl: x=x.to(device); y=y.to(device); opt.zero_grad(); o=model(x); lb=bce(o,y); ld=dice_loss(o,y); loss=lb+ld; loss.backward(); opt.step(); tb+=lb.item(); td+=ld.item()\n",
    "    model.eval(); vb=0; vd=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_dl: x=x.to(device); y=y.to(device); o=model(x); vb+=bce(o,y).item(); vd+=dice_loss(o,y).item()\n",
    "    train_hist.append((tb/len(train_dl), td/len(train_dl))); val_hist.append((vb/len(val_dl), vd/len(val_dl)))\n",
    "    print(f'Epoch {ep}/{EPOCHS} Train BCE {train_hist[-1][0]:.4f} Dice {train_hist[-1][1]:.4f} | Val BCE {val_hist[-1][0]:.4f} Dice {val_hist[-1][1]:.4f}')\n",
    "# -------- 後處理: 去除噪點並膨脹大區域邊緣 --------\n",
    "def postprocess_mask(mask_binary, min_area=50, dilate_kernel=5):\n",
    "    \"\"\"\n",
    "    mask_binary: (H,W) 0/1 mask, 1=缺陷\n",
    "    返回: 清理後的 mask (0/1)\n",
    "    \"\"\"\n",
    "    # 連通域分析\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_binary, connectivity=8)\n",
    "    cleaned = np.zeros_like(mask_binary)\n",
    "    \n",
    "    for i in range(1, num_labels):  # 跳過背景 (label 0)\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area < min_area:\n",
    "            # 小於閾值視為噪點，移除\n",
    "            continue\n",
    "        else:\n",
    "            # 保留大區域並進行邊緣膨脹\n",
    "            component = (labels == i).astype(np.uint8)\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_kernel, dilate_kernel))\n",
    "            dilated = cv2.dilate(component, kernel, iterations=1)\n",
    "            cleaned = cv2.bitwise_or(cleaned, dilated)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# -------- 生成預測與視覺化 --------\n",
    "def predict(im):\n",
    "    im_n=texture_normalize(im); t=torch.from_numpy(im_n.astype(np.float32)/255.0)[None,None,...].to(device)\n",
    "    with torch.no_grad(): p=torch.sigmoid(model(t))[0,0].cpu().numpy()\n",
    "    mask_raw=(p>0.5).astype(np.uint8) # 1=缺陷\n",
    "    # 應用後處理\n",
    "    mask_clean = postprocess_mask(mask_raw, min_area=30, dilate_kernel=5)\n",
    "    mask_out=np.ones_like(im_n,dtype=np.uint8)*255; mask_out[mask_clean==1]=0\n",
    "    return mask_out, p, mask_raw\n",
    "\n",
    "fig,axs=plt.subplots(len(imgs),5,figsize=(22,5*len(imgs)))\n",
    "if len(imgs)==1: axs=axs.reshape(1,5)\n",
    "for i,(im,gt) in enumerate(zip(imgs,gts)):\n",
    "    pm,prob,mask_raw=predict(im); im_norm=texture_normalize(im)\n",
    "    gt_def=(gt==0); pred_def=(pm==0)\n",
    "    raw_def=(mask_raw==1)\n",
    "    tp=int(np.logical_and(gt_def,pred_def).sum()); fp=int(np.logical_and(~gt_def,pred_def).sum()); fn=int(np.logical_and(gt_def,~pred_def).sum())\n",
    "    prec=tp/(tp+fp) if (tp+fp)>0 else 0; rec=tp/(tp+fn) if (tp+fn)>0 else 0; f1=(2*prec*rec)/(prec+rec) if (prec+rec)>0 else 0\n",
    "    axs[i,0].imshow(im,cmap='gray'); axs[i,0].set_title(f'原始 {i+1}'); axs[i,0].axis('off')\n",
    "    axs[i,1].imshow(im_norm,cmap='gray'); axs[i,1].set_title('改良紋理正規化'); axs[i,1].axis('off')\n",
    "    # 顯示原始預測 (後處理前)\n",
    "    mask_raw_display=np.ones_like(im,dtype=np.uint8)*255; mask_raw_display[raw_def]=0\n",
    "    axs[i,2].imshow(mask_raw_display,cmap='gray',vmin=0,vmax=255); axs[i,2].set_title('原始預測(有噪點)'); axs[i,2].axis('off')\n",
    "    # 顯示後處理結果\n",
    "    axs[i,3].imshow(pm,cmap='gray',vmin=0,vmax=255); axs[i,3].set_title('後處理(黑=缺陷)'); axs[i,3].axis('off')\n",
    "    overlay=np.stack([im]*3,axis=-1)\n",
    "    ov=overlay.copy(); ov[gt_def]=[0,255,0]; ov[pred_def]=[255,0,0]\n",
    "    axs[i,4].imshow(ov); axs[i,4].set_title(f'Overlay F1={f1:.3f}'); axs[i,4].axis('off')\n",
    "plt.tight_layout(); plt.show()\n",
    "# Loss 曲線\n",
    "tr_b=[x[0] for x in train_hist]; tr_d=[x[1] for x in train_hist]; va_b=[x[0] for x in val_hist]; va_d=[x[1] for x in val_hist]\n",
    "plt.figure(figsize=(10,4)); plt.subplot(1,2,1); plt.plot(tr_b,label='Train BCE'); plt.plot(va_b,label='Val BCE'); plt.legend(); plt.title('BCE Loss');\n",
    "plt.subplot(1,2,2); plt.plot(tr_d,label='Train Dice'); plt.plot(va_d,label='Val Dice'); plt.legend(); plt.title('Dice Loss'); plt.tight_layout(); plt.show()\n",
    "print('完成: 產生擴增資料並訓練模型。缺陷以黑色顯示。已加入後處理去除噪點並膨脹大區域邊緣。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df31d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images found: 2 in ./real_test_images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.ndim==\u001b[32m3\u001b[39m:\n\u001b[32m     27\u001b[39m     im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m mask_out, prob, mask_raw = \u001b[43mpredict\u001b[49m(im)\n\u001b[32m     30\u001b[39m name = Path(fp).stem\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 儲存後處理後的二值遮罩 (黑=缺陷, 白=背景)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "# 實際測試資料推論並輸出結果 + 圖像化\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "import cv2, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TEST_DIR = './real_test_images'\n",
    "OUT_DIR = './results_real'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 讀取所有影像 (支援常見副檔名)\n",
    "exts = ('*.png','*.jpg','*.jpeg','*.bmp','*.tif','*.tiff')\n",
    "files = []\n",
    "for ext in exts:\n",
    "    files += glob.glob(os.path.join(TEST_DIR, ext))\n",
    "files = sorted(files)\n",
    "print(f'Test images found: {len(files)} in {TEST_DIR}')\n",
    "\n",
    "# 推論並儲存結果\n",
    "summary = []\n",
    "for fp in files:\n",
    "    im = cv2.imread(fp, cv2.IMREAD_UNCHANGED)\n",
    "    if im is None:\n",
    "        print('Skip unreadable:', fp)\n",
    "        continue\n",
    "    if im.ndim==3:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    mask_out, prob, mask_raw = predict(im)\n",
    "\n",
    "    name = Path(fp).stem\n",
    "    # 儲存後處理後的二值遮罩 (黑=缺陷, 白=背景)\n",
    "    cv2.imwrite(os.path.join(OUT_DIR, f'{name}_mask.png'), mask_out)\n",
    "    # 儲存原始預測 (0/1) 便於除錯\n",
    "    raw_vis = np.ones_like(im, dtype=np.uint8)*255\n",
    "    raw_vis[mask_raw==1] = 0\n",
    "    cv2.imwrite(os.path.join(OUT_DIR, f'{name}_raw.png'), raw_vis)\n",
    "    # 儲存機率圖 (0-255 灰階)\n",
    "    prob_u8 = np.clip(prob*255, 0, 255).astype(np.uint8)\n",
    "    cv2.imwrite(os.path.join(OUT_DIR, f'{name}_prob.png'), prob_u8)\n",
    "    # 儲存疊圖\n",
    "    overlay = np.stack([im]*3, axis=-1)\n",
    "    ov = overlay.copy()\n",
    "    ov[mask_out==0] = [255,0,0]\n",
    "    cv2.imwrite(os.path.join(OUT_DIR, f'{name}_overlay.png'), ov)\n",
    "\n",
    "    summary.append((name, fp))\n",
    "\n",
    "# 視覺化：每張圖顯示 原始/原始預測/後處理遮罩/機率圖\n",
    "n_show = len(summary)\n",
    "if n_show>0:\n",
    "    fig, axs = plt.subplots(n_show, 4, figsize=(16, 4*n_show))\n",
    "    if n_show==1:\n",
    "        axs = axs.reshape(1,4)\n",
    "    for i in range(n_show):\n",
    "        name, fp = summary[i]\n",
    "        im = cv2.imread(fp, cv2.IMREAD_UNCHANGED)\n",
    "        if im.ndim==3:\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        mask_out = cv2.imread(os.path.join(OUT_DIR, f'{name}_mask.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        raw_vis = cv2.imread(os.path.join(OUT_DIR, f'{name}_raw.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        prob_u8 = cv2.imread(os.path.join(OUT_DIR, f'{name}_prob.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        axs[i,0].imshow(im, cmap='gray'); axs[i,0].set_title(f'原始 {name}'); axs[i,0].axis('off')\n",
    "        axs[i,1].imshow(raw_vis, cmap='gray', vmin=0, vmax=255); axs[i,1].set_title('原始預測'); axs[i,1].axis('off')\n",
    "        axs[i,2].imshow(mask_out, cmap='gray', vmin=0, vmax=255); axs[i,2].set_title('後處理遮罩'); axs[i,2].axis('off')\n",
    "        axs[i,3].imshow(prob_u8, cmap='gray'); axs[i,3].set_title('機率圖'); axs[i,3].axis('off')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# 額外總覽：疊圖畫廊（最多 12 張），便於快速巡檢\n",
    "max_gallery = min(12, n_show)\n",
    "if max_gallery>0:\n",
    "    cols = 4\n",
    "    rows = int(np.ceil(max_gallery/cols))\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(4*cols, 3*rows))\n",
    "    axs = np.array(axs)\n",
    "    axs = axs.reshape(rows, cols)\n",
    "    for i in range(rows*cols):\n",
    "        r = i//cols; c = i%cols\n",
    "        if i < max_gallery:\n",
    "            name, fp = summary[i]\n",
    "            overlay = cv2.imread(os.path.join(OUT_DIR, f'{name}_overlay.png'), cv2.IMREAD_UNCHANGED)\n",
    "            if overlay is None:\n",
    "                axs[r,c].axis('off'); continue\n",
    "            overlay_rgb = overlay[:,:,::-1] if overlay.ndim==3 else overlay\n",
    "            axs[r,c].imshow(overlay_rgb)\n",
    "            axs[r,c].set_title(name)\n",
    "            axs[r,c].axis('off')\n",
    "        else:\n",
    "            axs[r,c].axis('off')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "print(f'Inference done. Outputs saved to {OUT_DIR}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
